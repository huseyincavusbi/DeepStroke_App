{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 12128762,
          "sourceType": "datasetVersion",
          "datasetId": 7637522
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "y-g5cNB2gIQw"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/code/huseyincavus/deepstroke-se-resnext50/notebook"
      ],
      "metadata": {
        "id": "N3v_TfvYgIuD"
      }
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "huseyincavus_deepstroke_path = kagglehub.dataset_download('huseyincavus/deepstroke')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "9JQXx5XYgIQx"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Display random images from the dataset\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Define the data directories\n",
        "base_dir = \"/kaggle/input/deepstroke/DeepStroke1_Data\"\n",
        "ischaemic_dir = os.path.join(base_dir, \"Ischaemic\")\n",
        "non_ischaemic_dir = os.path.join(base_dir, \"Non-Ischaemic\")\n",
        "hemoraj_dir = os.path.join(base_dir, \"Hemoraj\")\n",
        "\n",
        "def display_random_images(directory, num_images=4):\n",
        "    if not os.path.exists(directory):\n",
        "        print(f\"Directory not found: {directory}\")\n",
        "        return\n",
        "\n",
        "    all_files = os.listdir(directory)\n",
        "    # Filter out non-image files\n",
        "    image_files = [f for f in all_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"No image files found in {directory}\")\n",
        "        return\n",
        "\n",
        "    random_files = random.sample(image_files, min(num_images, len(image_files)))\n",
        "\n",
        "    # Create a figure and axes for the subplots\n",
        "    fig, axes = plt.subplots(1, len(random_files), figsize=(15, 5))\n",
        "    if len(random_files) == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    # Display each image in a subplot\n",
        "    for i, file in enumerate(random_files):\n",
        "        image_path = os.path.join(directory, file)\n",
        "        img = mpimg.imread(image_path)\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_title(os.path.basename(file))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display Ischaemic images\n",
        "if os.path.exists(ischaemic_dir):\n",
        "    print(\"Ischaemic Images:\")\n",
        "    print(f\"Number of Ischaemic samples: {len(os.listdir(ischaemic_dir))}\")\n",
        "    display_random_images(ischaemic_dir)\n",
        "else:\n",
        "    print(f\"Directory not found: {ischaemic_dir}\")\n",
        "\n",
        "# Display Non-Ischaemic images\n",
        "if os.path.exists(non_ischaemic_dir):\n",
        "    print(\"\\nNon-Ischaemic Images:\")\n",
        "    print(f\"Number of Non-Ischemic samples: {len(os.listdir(non_ischaemic_dir))}\")\n",
        "    display_random_images(non_ischaemic_dir)\n",
        "else:\n",
        "    print(f\"Directory not found: {non_ischaemic_dir}\")\n",
        "\n",
        "# Display Hemoraj images\n",
        "if os.path.exists(hemoraj_dir):\n",
        "    print(\"\\nHemoraj Images:\")\n",
        "\n",
        "    # Check if Hemoraj has subdirectories (class folders)\n",
        "    subdirs = [d for d in os.listdir(hemoraj_dir) if os.path.isdir(os.path.join(hemoraj_dir, d))]\n",
        "\n",
        "    if subdirs:  # If there are subdirectories (class folders)\n",
        "        for subdir in subdirs:\n",
        "            class_dir = os.path.join(hemoraj_dir, subdir)\n",
        "            print(f\"-- {subdir} Images:\")\n",
        "            print(f\"   Number of {subdir} samples: {len(os.listdir(class_dir))}\")\n",
        "            display_random_images(class_dir)\n",
        "    else:  # If images are directly in the base directory\n",
        "        print(f\"Number of samples: {len([f for f in os.listdir(hemoraj_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])}\")\n",
        "        display_random_images(hemoraj_dir)\n",
        "else:\n",
        "    print(f\"Directory not found: {hemoraj_dir}\")"
      ],
      "metadata": {
        "id": "E_hVhkJtX0Qc",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T09:23:49.210399Z",
          "iopub.execute_input": "2025-06-11T09:23:49.21068Z",
          "iopub.status.idle": "2025-06-11T09:23:54.643448Z",
          "shell.execute_reply.started": "2025-06-11T09:23:49.210656Z",
          "shell.execute_reply": "2025-06-11T09:23:54.642689Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Prepare the dataset for training (Optimized for Speed)\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- OPTIMIZATION: Get the number of available CPU cores ---\n",
        "# This will be used to parallelize data loading.\n",
        "try:\n",
        "    NUM_CPUS = os.cpu_count()\n",
        "except:\n",
        "    NUM_CPUS = 4 # A reasonable fallback for platforms where os.cpu_count() might fail\n",
        "\n",
        "# Constants for ResNet50\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "BATCH_SIZE = 128 # Increased for better GPU utilization\n",
        "\n",
        "# ImageNet normalization values for ResNet50\n",
        "MEAN = [0.485, 0.456, 0.406]\n",
        "STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Setup device for GPU usage\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Using {NUM_CPUS} CPU workers for data loading.\")\n",
        "\n",
        "# DeepStroke dataset paths\n",
        "base_dir = \"/kaggle/input/deepstroke/DeepStroke1_Data\"\n",
        "normal_dir = os.path.join(base_dir, \"Non-Ischaemic\")  # Normal images (label 0)\n",
        "abnormal_dirs = [\n",
        "    os.path.join(base_dir, \"Ischaemic\"),  # Abnormal images (label 1)\n",
        "    os.path.join(base_dir, \"Hemoraj\")     # Abnormal images (label 1)\n",
        "]\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, normal_dir, abnormal_dirs, transform=None):\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Add normal images (label 0)\n",
        "        if os.path.exists(normal_dir):\n",
        "            for f in os.listdir(normal_dir):\n",
        "                if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.image_paths.append(os.path.join(normal_dir, f))\n",
        "                    self.labels.append(0)  # Normal\n",
        "\n",
        "        # Add abnormal images (label 1)\n",
        "        for abnormal_dir in abnormal_dirs:\n",
        "            if os.path.exists(abnormal_dir):\n",
        "                for f in os.listdir(abnormal_dir):\n",
        "                    if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                        self.image_paths.append(os.path.join(abnormal_dir, f))\n",
        "                        self.labels.append(1)  # Abnormal\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Define the transformations for training and for validation/testing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD)\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_HEIGHT, IMG_WIDTH)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD)\n",
        "])\n",
        "\n",
        "# Create dataset with augmented images for training\n",
        "dataset = ImageDataset(normal_dir, abnormal_dirs, transform=train_transform)\n",
        "\n",
        "# Split dataset into training (70%), validation (15%), and test (15%)\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=generator)\n",
        "\n",
        "# --- Oversampling for Training Set ---\n",
        "train_indices = train_dataset.indices\n",
        "normal_indices = [i for i in train_indices if dataset[i][1].item() == 0]\n",
        "abnormal_indices = [i for i in train_indices if dataset[i][1].item() == 1]\n",
        "\n",
        "num_normal = len(normal_indices)\n",
        "num_abnormal = len(abnormal_indices)\n",
        "print(f\"Training set before balancing: Normal={num_normal}, Abnormal={num_abnormal}\")\n",
        "\n",
        "if num_normal < num_abnormal:\n",
        "    oversampled_indices = random.choices(normal_indices, k=num_abnormal - num_normal)\n",
        "    new_train_indices = train_indices + oversampled_indices\n",
        "    print(f\"Oversampling Normal class: added {len(oversampled_indices)} samples\")\n",
        "elif num_abnormal < num_normal:\n",
        "    oversampled_indices = random.choices(abnormal_indices, k=num_normal - num_abnormal)\n",
        "    new_train_indices = train_indices + oversampled_indices\n",
        "    print(f\"Oversampling Abnormal class: added {len(oversampled_indices)} samples\")\n",
        "else:\n",
        "    new_train_indices = train_indices\n",
        "    print(\"Classes are already balanced\")\n",
        "\n",
        "random.shuffle(new_train_indices)\n",
        "train_dataset = torch.utils.data.Subset(dataset, new_train_indices)\n",
        "\n",
        "# Create an \"original\" dataset for displaying purposes\n",
        "original_dataset = ImageDataset(normal_dir, abnormal_dirs, transform=None)\n",
        "original_train_dataset = torch.utils.data.Subset(original_dataset, new_train_indices)\n",
        "\n",
        "# Create datasets with validation/test transforms\n",
        "val_dataset_with_transform = torch.utils.data.Subset(\n",
        "    ImageDataset(normal_dir, abnormal_dirs, transform=val_test_transform),\n",
        "    val_dataset.indices\n",
        ")\n",
        "test_dataset_with_transform = torch.utils.data.Subset(\n",
        "    ImageDataset(normal_dir, abnormal_dirs, transform=val_test_transform),\n",
        "    test_dataset.indices\n",
        ")\n",
        "\n",
        "# --- OPTIMIZATION: Create DataLoaders using multiple CPU cores ---\n",
        "# num_workers > 0 enables multi-process data loading.\n",
        "# pin_memory=True speeds up CPU to GPU data transfer.\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=NUM_CPUS)\n",
        "val_loader = DataLoader(val_dataset_with_transform, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=NUM_CPUS)\n",
        "test_loader = DataLoader(test_dataset_with_transform, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True, num_workers=NUM_CPUS)\n",
        "\n",
        "\n",
        "# The rest of the cell remains the same...\n",
        "# Count images per class in the full dataset\n",
        "normal_count = sum(1 for _, label in dataset if label.item() == 0)\n",
        "abnormal_count = sum(1 for _, label in dataset if label.item() == 1)\n",
        "\n",
        "print(f\"\\nFull dataset:\")\n",
        "print(f\"Number of normal images: {normal_count}\")\n",
        "print(f\"Number of abnormal images: {abnormal_count}\")\n",
        "print(f\"Total images: {len(dataset)}\")\n",
        "\n",
        "class_names = [\"Normal\", \"Abnormal\"]\n",
        "\n",
        "def display_random_images_from_dataset(dataset, save=False, filename=\"random_images.png\", num_images=4):\n",
        "    indices = random.sample(range(len(dataset)), min(num_images, len(dataset)))\n",
        "    fig, axes = plt.subplots(1, len(indices), figsize=(15, 5))\n",
        "    if len(indices) == 1:\n",
        "        axes = [axes]\n",
        "    for i, idx in enumerate(indices):\n",
        "        image, label = dataset[idx]\n",
        "        image = image.cpu() if isinstance(image, torch.Tensor) and image.device.type != 'cpu' else image\n",
        "        if isinstance(image, torch.Tensor):\n",
        "            image = image.cpu().numpy().transpose((1, 2, 0))\n",
        "            image = image * np.array(STD) + np.array(MEAN)\n",
        "            image = np.clip(image, 0, 1)\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].axis('off')\n",
        "        label_idx = label.item() if torch.is_tensor(label) else label\n",
        "        axes[i].set_title(f\"Label: {class_names[label_idx]}\")\n",
        "    plt.tight_layout()\n",
        "    if save:\n",
        "        plt.savefig(filename)\n",
        "        print(f\"Saved random images to {filename}\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nRandom Images from Training Set:\")\n",
        "display_random_images_from_dataset(train_dataset, save=False, filename=\"random_train_images.png\")\n",
        "\n",
        "def display_augmented_images(original_dataset, augmented_dataset, save=False, base_filename=\"augmented_\", num_images=4):\n",
        "    indices = random.sample(range(len(original_dataset)), min(num_images, len(original_dataset)))\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        orig_image, label = original_dataset[idx]\n",
        "        label_idx = label.item() if torch.is_tensor(label) else label\n",
        "        file_path = original_dataset.dataset.image_paths[original_dataset.indices[idx]]\n",
        "\n",
        "        augmented_images = []\n",
        "        for _ in range(10):\n",
        "            augmented_image, _ = augmented_dataset[idx]\n",
        "            augmented_images.append(augmented_image)\n",
        "\n",
        "        fig_aug, axes_aug = plt.subplots(2, 5, figsize=(15, 6))\n",
        "        fig_aug.suptitle(f\"Class: {class_names[label_idx]}\\nFilename: {os.path.basename(file_path)}\", fontsize=14)\n",
        "        axes_aug = axes_aug.flatten()\n",
        "\n",
        "        for j, aug_img in enumerate(augmented_images):\n",
        "            aug_disp = aug_img.numpy().transpose((1, 2, 0))\n",
        "            aug_disp = aug_disp * np.array(STD) + np.array(MEAN)\n",
        "            aug_disp = np.clip(aug_disp, 0, 1)\n",
        "            axes_aug[j].imshow(aug_disp)\n",
        "            axes_aug[j].axis('off')\n",
        "            axes_aug[j].set_title(f\"Augmented {j+1}\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        if save:\n",
        "            out_filename = f\"{base_filename}{class_names[label_idx]}_{i+1}.png\"\n",
        "            plt.savefig(out_filename)\n",
        "        plt.show()\n",
        "\n",
        "print(\"\\nSome Augmented Images:\")\n",
        "display_augmented_images(original_train_dataset, train_dataset, save=False)"
      ],
      "metadata": {
        "id": "mLGvtdz6X0Qe",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T09:59:02.189054Z",
          "iopub.execute_input": "2025-06-11T09:59:02.189649Z",
          "iopub.status.idle": "2025-06-11T10:05:07.493857Z",
          "shell.execute_reply.started": "2025-06-11T09:59:02.189616Z",
          "shell.execute_reply": "2025-06-11T10:05:07.493183Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.synchronize()  # optional: waits for all kernels to finish"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T10:05:42.242558Z",
          "iopub.execute_input": "2025-06-11T10:05:42.242855Z",
          "iopub.status.idle": "2025-06-11T10:05:42.246728Z",
          "shell.execute_reply.started": "2025-06-11T10:05:42.242834Z",
          "shell.execute_reply": "2025-06-11T10:05:42.246031Z"
        },
        "id": "bwhjOi91gIQz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torchvision.models.resnet import Bottleneck\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "# --- OPTIMIZATION: Import for Automatic Mixed Precision (AMP) ---\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# --- OPTIMIZATION: Configuration updated for new batch size ---\n",
        "num_epochs = 30\n",
        "patience = 5\n",
        "# Batch size was 32, now 128 (4x). Scale learning rate by 4x.\n",
        "learning_rate = 4e-4  # Previously 1e-4\n",
        "weight_decay = 1e-4\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Learning rate adjusted to {learning_rate} for larger batch size.\")\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "        self.criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = self.criterion(inputs, targets)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = self.alpha * (1 - pt)**self.gamma * BCE_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return torch.mean(F_loss)\n",
        "        elif self.reduction == 'sum':\n",
        "            return torch.sum(F_loss)\n",
        "        else:\n",
        "            return F_loss\n",
        "\n",
        "# --- Model Definition (No changes needed here) ---\n",
        "class SELayer(nn.Module):\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(nn.Linear(channel, channel // reduction, bias=False), nn.ReLU(inplace=True), nn.Linear(channel // reduction, channel, bias=False), nn.Sigmoid())\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size(); y = self.avg_pool(x).view(b, c); y = self.fc(y).view(b, c, 1, 1); return x * y.expand_as(x)\n",
        "\n",
        "class SEBottleneck(Bottleneck):\n",
        "    expansion = 4\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1, base_width=64, dilation=1, norm_layer=None, se_reduction=16):\n",
        "        super(SEBottleneck, self).__init__(inplanes, planes, stride, downsample, groups, base_width, dilation, norm_layer)\n",
        "        self.se = SELayer(planes * self.expansion, reduction=se_reduction)\n",
        "    def forward(self, x):\n",
        "        identity = x; out = self.conv1(x); out = self.bn1(out); out = self.relu(out); out = self.conv2(out); out = self.bn2(out); out = self.relu(out); out = self.conv3(out); out = self.bn3(out); out = self.se(out)\n",
        "        if self.downsample is not None: identity = self.downsample(x)\n",
        "        out += identity; out = self.relu(out); return out\n",
        "\n",
        "def get_seresnext50(num_classes=1, se_reduction=16):\n",
        "    model = models.resnext50_32x4d(pretrained=True); base_width = model.base_width\n",
        "    def replace_bottlenecks(module, se_reduction_ratio, base_width):\n",
        "        for name, child_module in module.named_children():\n",
        "            if isinstance(child_module, Bottleneck):\n",
        "                inplanes = child_module.conv1.in_channels; planes = child_module.conv3.out_channels // child_module.expansion; stride = child_module.stride; downsample = child_module.downsample; groups = child_module.conv2.groups; dilation = child_module.conv2.dilation[0]\n",
        "                new_bottleneck = SEBottleneck(inplanes=inplanes, planes=planes, stride=stride, downsample=downsample, groups=groups, base_width=base_width, dilation=dilation, se_reduction=se_reduction_ratio)\n",
        "                new_bottleneck.load_state_dict(child_module.state_dict(), strict=False); setattr(module, name, new_bottleneck)\n",
        "            else: replace_bottlenecks(child_module, se_reduction_ratio, base_width)\n",
        "    replace_bottlenecks(model, se_reduction, base_width)\n",
        "    in_features = model.fc.in_features; model.fc = nn.Linear(in_features, num_classes); return model\n",
        "\n",
        "# --- Initialization (No changes needed here) ---\n",
        "se_reduction_ratio = 16\n",
        "model = get_seresnext50(num_classes=1, se_reduction=se_reduction_ratio)\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(f\"Using {torch.cuda.device_count()} GPUs: {[torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]}\")\n",
        "    model = nn.DataParallel(model)\n",
        "model = model.to(device)\n",
        "criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "# --- OPTIMIZATION: Training function with Mixed Precision ---\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, patience, se_reduction=16):\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'lr': []}\n",
        "\n",
        "    # Initialize the gradient scaler for mixed precision\n",
        "    scaler = GradScaler()\n",
        "    print(\"Training with Automatic Mixed Precision (AMP) enabled.\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss, train_correct, train_total = 0.0, 0, 0\n",
        "        pbar_train = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
        "        for inputs, labels in pbar_train:\n",
        "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True).float().view(-1, 1)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Use autocast for the forward pass\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Scale the loss and call backward()\n",
        "            scaler.scale(loss).backward()\n",
        "            # Unscale the gradients and call optimizer.step()\n",
        "            scaler.step(optimizer)\n",
        "            # Update the scaler for the next iteration\n",
        "            scaler.update()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "            pbar_train.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        # ... (rest of the training loop is the same) ...\n",
        "\n",
        "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
        "        epoch_train_acc = train_correct / train_total\n",
        "        history['train_loss'].append(epoch_train_loss)\n",
        "        history['train_acc'].append(epoch_train_acc)\n",
        "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "        # Validation phase (autocast is recommended here too for consistency and speed)\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            pbar_val = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')\n",
        "            for inputs, labels in pbar_val:\n",
        "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True).float().view(-1, 1)\n",
        "                with autocast():\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "                pbar_val.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "        epoch_val_acc = val_correct / val_total\n",
        "        history['val_loss'].append(epoch_val_loss)\n",
        "        history['val_acc'].append(epoch_val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
        "        scheduler.step(epoch_val_loss)\n",
        "\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            best_val_loss = epoch_val_loss\n",
        "            patience_counter = 0\n",
        "            checkpoint = {'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'scheduler_state_dict': scheduler.state_dict(), 'epoch': epoch, 'val_loss': best_val_loss, 'history': history, 'config': {'learning_rate': learning_rate, 'weight_decay': weight_decay, 'batch_size': train_loader.batch_size, 'se_reduction_ratio': se_reduction}}\n",
        "            torch.save(checkpoint, 'best_seresnext50_model.pth')\n",
        "            print(f\"Model improved! Saved checkpoint at epoch {epoch+1}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"Model didn't improve for {patience_counter}/{patience} epochs\")\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "                break\n",
        "\n",
        "    # Save final model regardless of performance\n",
        "    final_checkpoint = {'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'scheduler_state_dict': scheduler.state_dict(), 'epoch': epoch, 'val_loss': epoch_val_loss, 'history': history, 'config': {'learning_rate': learning_rate, 'weight_decay': weight_decay, 'batch_size': train_loader.batch_size, 'se_reduction_ratio': se_reduction}}\n",
        "    torch.save(final_checkpoint, 'final_seresnext50_model.pth')\n",
        "    with open('seresnext50_training_history.pkl', 'wb') as f:\n",
        "        pickle.dump(history, f)\n",
        "    if os.path.exists('best_seresnext50_model.pth'):\n",
        "        checkpoint = torch.load('best_seresnext50_model.pth')\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    return model, history\n",
        "\n",
        "# Start training\n",
        "model, history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=num_epochs,\n",
        "    patience=patience,\n",
        "    se_reduction=se_reduction_ratio\n",
        ")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.subplot(2, 2, 1); plt.plot(history['train_loss'], label='Training Loss'); plt.plot(history['val_loss'], label='Validation Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss Curves')\n",
        "plt.subplot(2, 2, 2); plt.plot(history['train_acc'], label='Training Accuracy'); plt.plot(history['val_acc'], label='Validation Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.title('Accuracy Curves')\n",
        "plt.subplot(2, 2, 3); plt.plot(history['lr']); plt.xlabel('Epoch'); plt.ylabel('Learning Rate'); plt.title('Learning Rate Schedule')\n",
        "plt.subplot(2, 2, 4); plt.axis('off'); info_text = (f\"Model: SE-ResNeXt50\\nSE Reduction Ratio: {se_reduction_ratio}\\nOptimizer: AdamW\\nInitial LR: {learning_rate}\\nWeight Decay: {weight_decay}\\nLoss: Focal Loss (α={criterion.alpha}, γ={criterion.gamma})\"); plt.text(0.1, 0.5, info_text, fontsize=12)\n",
        "plt.tight_layout(); plt.savefig(f'seresnext50_r{se_reduction_ratio}_training_plots.png', dpi=300); plt.show()\n",
        "print(f\"Training completed! SE-ResNeXt50 with reduction ratio {se_reduction_ratio}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-11T10:05:48.487763Z",
          "iopub.execute_input": "2025-06-11T10:05:48.488061Z",
          "iopub.status.idle": "2025-06-11T10:28:31.578634Z",
          "shell.execute_reply.started": "2025-06-11T10:05:48.488041Z",
          "shell.execute_reply": "2025-06-11T10:28:31.577803Z"
        },
        "id": "HjN6hDXCgIQ0"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}